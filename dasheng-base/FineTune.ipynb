{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f4dcce4-34e2-4c49-be70-899b69c5b693",
   "metadata": {},
   "source": [
    "**dasheng-base does not support variable length audio inputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dc352de-f7eb-4b47-9c73-d9d94f49a935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dasheng_model.feature_extraction_dasheng import DashengFeatureExtractor\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Audio\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "406ffc8d-8186-4c61-ab77-5b64cf17a8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../config.json\", mode = \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    SAMPLING_RATE = data[\"sampling_rate\"]\n",
    "    SEGMENT_LEN = data[\"segment_length\"]\n",
    "    OVERLAP_LEN = data[\"overlap_length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75a5162c-7255-4453-b355-ec39efa891b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/labnet5/gr5/abahari/Documents/Fridays/BirdCallLabeling/env-labeling/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "extractor = DashengFeatureExtractor.from_pretrained(\"mispeech/dasheng-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95dba805-d4d4-432d-8cd7-b9a765450742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff6c29068c8a47c0afb22cac7d02c0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/11032 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"Saads/xecanto_birds\", split = \"train\")\n",
    "dataset = dataset.class_encode_column(\"common_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ffba230-6c2e-48fa-81a8-680b00c3b7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset.features[\"common_name\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3df7849f-daf1-4ae8-959d-da64c69ba633",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9568536-9be3-4d63-a128-7cd773a782ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio', 'common_name'],\n",
       "        num_rows: 8824\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['audio', 'common_name'],\n",
       "        num_rows: 2207\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.remove_columns([\n",
    "    \"primary_label\",\n",
    "    \"secondary_labels\",\n",
    "    \"scientific_name\",\n",
    "    \"author\",\n",
    "    \"license\",\n",
    "    \"rating\",\n",
    "    \"type\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"url\"\n",
    "])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b1f9043-c60a-4452-82a1-93166f8b7788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': [{'path': '/users/labnet5/gr5/abahari/.cache/huggingface/hub/datasets--Saads--xecanto_birds/snapshots/a0cca0425468f94c84acd14479327b43c3c06084/mabeat1/XC591667.ogg',\n",
       "   'array': array([-3.12357679e-06,  9.21771857e-07,  1.82094045e-05, ...,\n",
       "           2.39509536e-05,  9.46432010e-06, -1.19023462e-05]),\n",
       "   'sampling_rate': 32000},\n",
       "  {'path': '/users/labnet5/gr5/abahari/.cache/huggingface/hub/datasets--Saads--xecanto_birds/snapshots/a0cca0425468f94c84acd14479327b43c3c06084/abethr1/XC363503.ogg',\n",
       "   'array': array([ 1.38384030e-06, -1.17889140e-05,  1.05290583e-05, ...,\n",
       "          -1.04965176e-04, -1.32110901e-04, -3.10554635e-04]),\n",
       "   'sampling_rate': 32000},\n",
       "  {'path': '/users/labnet5/gr5/abahari/.cache/huggingface/hub/datasets--Saads--xecanto_birds/snapshots/a0cca0425468f94c84acd14479327b43c3c06084/eaywag1/XC118267.ogg',\n",
       "   'array': array([-3.12964548e-05, -2.68409913e-05, -9.95137452e-06, ...,\n",
       "           2.18505065e-05,  1.52069197e-05, -2.19970061e-05]),\n",
       "   'sampling_rate': 32000}],\n",
       " 'common_name': [141, 1, 228]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcff1f8a-67b4-455f-86e6-ec113c49cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chunked_audio(audio_array, chunk_length = SEGMENT_LEN, overlap = OVERLAP_LEN):\n",
    "    chunk_length = chunk_length * SAMPLING_RATE\n",
    "    overlap = overlap * SAMPLING_RATE\n",
    "    \n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start + chunk_length <= len(audio_array):\n",
    "        chunks.append(\n",
    "            extractor(\n",
    "                audio_array[start : start + chunk_length],\n",
    "                sampling_rate = SAMPLING_RATE,\n",
    "                max_length = chunk_length,\n",
    "                truncation = True\n",
    "            )[\"input_values\"].squeeze(0)\n",
    "        )\n",
    "        start += (chunk_length - overlap)\n",
    "    \n",
    "    if start < len(audio_array):\n",
    "        last_chunk = audio_array[start:]\n",
    "        padded_last_chunk = np.pad(last_chunk, (0, chunk_length - len(last_chunk)))\n",
    "        chunks.append(\n",
    "            extractor(\n",
    "                padded_last_chunk,\n",
    "                sampling_rate = SAMPLING_RATE,\n",
    "                max_length = chunk_length,\n",
    "                truncation = True\n",
    "            )[\"input_values\"].squeeze(0)\n",
    "        )\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54020c53-2159-4270-8f9e-c41b8f363696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(row):\n",
    "    chunked_batched_data = {}\n",
    "    inputs = extract_chunked_audio(row[\"audio\"][\"array\"])\n",
    "    chunked_batched_data[\"input_values\"] = inputs\n",
    "    chunked_batched_data[\"common_name\"] = [row[\"common_name\"]] * len(inputs)\n",
    "    return chunked_batched_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdd2b777-ea54-4570-b3f2-dfe9a4cc12db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concate(batch):\n",
    "   return {\n",
    "       \"concate_input_values\": [chunk for chunks in batch[\"input_values\"] for chunk in chunks],\n",
    "       \"chunked_common_name\": [label for chunks in batch[\"common_name\"] for label in chunks]\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff670d57-8320-42eb-98c4-6c23fe485789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40392686ee64b28a30fa8a0d5ec35f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/8824 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f236f1f5364380a2fe98b722843708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/2207 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46c877183b94f39a91ad866a15f7564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/8824 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4efbc5c8b2c44b03a3a9ea623fc43840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/2207 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate = SAMPLING_RATE))\n",
    "dataset = dataset.map(\n",
    "    preprocess,\n",
    "    remove_columns = \"audio\",\n",
    "    batched = False,\n",
    "    num_proc = 16,\n",
    "    writer_batch_size = 500 #200\n",
    ")\n",
    "dataset = dataset.map(\n",
    "    concate,\n",
    "    remove_columns = [\"input_values\", \"common_name\"],\n",
    "    batched = True,\n",
    "    batch_size = 16,\n",
    "    num_proc = 16,\n",
    "    writer_batch_size = 500 #100\n",
    ")\n",
    "len(dataset[\"train\"][0][\"concate_input_values\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3635a6de-7192-4891-addb-9c0ee8231522",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename_column(\"concate_input_values\", \"input_values\")\n",
    "dataset = dataset.rename_column(\"chunked_common_name\", \"label\")\n",
    "dataset = dataset.shuffle(seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20f8e5cd-6181-4fba-a273-58ecdd597ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd1ddf25-1a26-4ae6-973a-e9d6420633d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/labnet5/gr5/abahari/Documents/Fridays/BirdCallLabeling/env-labeling/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541267145e7f4fac8d4fc24a278e9c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/391 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d559ee3b40af44348b2fc281cbccbdd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/342M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DashengModel were not initialized from the model checkpoint at mispeech/dasheng-base and are newly initialized: ['outputlayer.0.bias', 'outputlayer.1.weight', 'outputlayer.1.bias', 'outputlayer.0.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from dasheng_model.modeling_dasheng import DashengModel\n",
    "\n",
    "model = DashengModel.from_pretrained(\n",
    "    \"mispeech/dasheng-base\",\n",
    "    outputdim = len(id2label),\n",
    "    num_labels = len(id2label),\n",
    "    label2id = label2id,\n",
    "    id2label = id2label\n",
    ")\n",
    "\n",
    "model.freeze_encoder()\n",
    "model.config.loss = \"CrossEntropyLoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4922f97-54cc-464e-b770-6ca2f356e073",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e89b93e4-75ec-4dfc-a50f-4799d7c366bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    # [0] added after .predictions!!!\n",
    "    predictions = np.argmax(eval_pred.predictions[0], axis = 1)\n",
    "    return accuracy.compute(predictions = predictions, references = eval_pred.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86409970-443d-412b-a8af-70cd0c914798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26510' max='26510' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26510/26510 2:15:27, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.995500</td>\n",
       "      <td>5.070867</td>\n",
       "      <td>0.198428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.908000</td>\n",
       "      <td>5.021171</td>\n",
       "      <td>0.255893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.865600</td>\n",
       "      <td>5.000422</td>\n",
       "      <td>0.277951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.851600</td>\n",
       "      <td>4.989946</td>\n",
       "      <td>0.294708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.854800</td>\n",
       "      <td>4.983718</td>\n",
       "      <td>0.298495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.806800</td>\n",
       "      <td>4.978000</td>\n",
       "      <td>0.305027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.772400</td>\n",
       "      <td>4.973799</td>\n",
       "      <td>0.315062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.765700</td>\n",
       "      <td>4.971040</td>\n",
       "      <td>0.323488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.764100</td>\n",
       "      <td>4.969545</td>\n",
       "      <td>0.320174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.780600</td>\n",
       "      <td>4.969994</td>\n",
       "      <td>0.320553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=26510, training_loss=4.851824414725575, metrics={'train_runtime': 8147.1207, 'train_samples_per_second': 52.044, 'train_steps_per_second': 3.254, 'total_flos': 1.3959849454373224e+19, 'train_loss': 4.851824414725575, 'epoch': 10.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = \"checkpoints-10-2\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate = 5e-4,\n",
    "    per_device_train_batch_size = 16,\n",
    "    # gradient_accumulation_steps = 4,\n",
    "    eval_accumulation_steps = 2,\n",
    "    per_device_eval_batch_size = 16,\n",
    "    num_train_epochs = 10,\n",
    "    warmup_ratio = 0,\n",
    "    logging_steps = 10,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = \"eval_loss\",\n",
    "    dataloader_num_workers = 16,\n",
    "    fp16 = True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = dataset[\"train\"],\n",
    "    eval_dataset = dataset[\"test\"],\n",
    "    tokenizer = extractor,\n",
    "    compute_metrics = compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eae030-d465-447d-b8ed-e3e0d7b73d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-labeling",
   "language": "python",
   "name": "env-labeling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
