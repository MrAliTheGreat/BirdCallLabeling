{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec3752fc-3cee-419a-839c-c5d16d98ab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor, AutoModelForAudioClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Audio\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a2dcfd9-ce88-47b6-be47-3fb1a871e53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../config.json\", mode = \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    SAMPLING_RATE = data[\"sampling_rate\"]\n",
    "    SEGMENT_LEN = data[\"segment_length\"]\n",
    "    OVERLAP_LEN = data[\"overlap_length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827cef0e-ab4f-42b7-a855-7611f6452cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-large-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea0fff9-c191-4f6a-bdff-8189d0c8fd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Saads/xecanto_birds\", split = \"train\")\n",
    "dataset = dataset.class_encode_column(\"common_name\")\n",
    "dataset = dataset.shuffle(seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf1916c-4408-4715-9e71-674982c583cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7828b7de-323e-4ee3-8a90-2ac72162f8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset.features[\"common_name\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2479b13-5536-4054-87ce-67b8c0e6bffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size = 0.2)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca4f197-8a31-4a8f-ae7e-ea7e3f410d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns([\n",
    "    \"primary_label\",\n",
    "    \"secondary_labels\",\n",
    "    \"scientific_name\",\n",
    "    \"author\",\n",
    "    \"license\",\n",
    "    \"rating\",\n",
    "    \"type\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"url\"\n",
    "])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2e51a5-dae6-4bbd-b338-87ed8d60739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0355b16c-2321-476c-9bb6-221dbde5c28d",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9760b57e-5754-437e-a5f0-9b32495112e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_audio(audio_array, chunk_length = SEGMENT_LEN, overlap = OVERLAP_LEN):\n",
    "    chunk_length = chunk_length * SAMPLING_RATE\n",
    "    overlap = overlap * SAMPLING_RATE\n",
    "    \n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start + chunk_length <= len(audio_array):\n",
    "        chunks.append(audio_array[start : start + chunk_length])\n",
    "        start += (chunk_length - overlap)\n",
    "    \n",
    "    if start < len(audio_array):\n",
    "        last_chunk = audio_array[start:]\n",
    "        padded_last_chunk = np.pad(last_chunk, (0, chunk_length - len(last_chunk)))\n",
    "        chunks.append(padded_last_chunk)\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e79872a-d3d4-41bc-a52c-0610b85b11b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(row):\n",
    "    chunked_batched_data = {}\n",
    "    chunks = chunk_audio(row[\"audio\"][\"array\"])\n",
    "    inputs = extractor(chunks, sampling_rate = SAMPLING_RATE)\n",
    "    chunked_batched_data[\"input_values\"] = inputs[\"input_values\"]\n",
    "    chunked_batched_data[\"common_name\"] = [row[\"common_name\"]] * len(chunks)\n",
    "    return chunked_batched_data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d32139-5305-425e-8f22-35099da95591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concate(batch):\n",
    "   return {\n",
    "       \"concate_input_values\": [chunk for chunks in batch[\"input_values\"] for chunk in chunks],\n",
    "       \"chunked_common_name\": [label for chunks in batch[\"common_name\"] for label in chunks]\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5511eb10-5ab6-49f3-b537-41f5e1b36177",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate = SAMPLING_RATE))\n",
    "dataset = dataset.map(\n",
    "    preprocess,\n",
    "    remove_columns = \"audio\",\n",
    "    batched = False,\n",
    "    num_proc = 16,\n",
    "    writer_batch_size = 200\n",
    ")\n",
    "dataset = dataset.map(\n",
    "    concate,\n",
    "    remove_columns = [\"input_values\", \"common_name\"],\n",
    "    batched = True,\n",
    "    batch_size = 16,\n",
    "    num_proc = 16,\n",
    "    writer_batch_size = 100\n",
    ")\n",
    "len(dataset[\"train\"][0][\"concate_input_values\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cff4b24-9458-4d10-85ec-299ac9d41dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename_column(\"concate_input_values\", \"input_values\")\n",
    "dataset = dataset.rename_column(\"chunked_common_name\", \"label\")\n",
    "dataset = dataset.shuffle(seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22841c92-bdfa-4981-a5e7-c146f21d9f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForAudioClassification.from_pretrained(\n",
    "    \"facebook/wav2vec2-large-960h\",\n",
    "    num_labels = len(id2label),\n",
    "    label2id = label2id,\n",
    "    id2label = id2label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf5e06f-3da7-443e-83fd-0bd684a5a14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bb89a9-c7b3-44ac-b5b1-d56e3f11153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions = np.argmax(eval_pred.predictions, axis = 1)\n",
    "    return accuracy.compute(predictions = predictions, references = eval_pred.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4535fe-6739-48e3-86ed-54ab09a46728",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = \"checkpoints-10-2\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate = 3e-5,\n",
    "    per_device_train_batch_size = 8,\n",
    "    # gradient_accumulation_steps = 4,\n",
    "    per_device_eval_batch_size = 8,\n",
    "    num_train_epochs = 7,\n",
    "    # warmup_ratio = 0.1,\n",
    "    logging_steps = 10,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = \"eval_loss\",\n",
    "    fp16 = True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = dataset[\"train\"],\n",
    "    eval_dataset = dataset[\"test\"],\n",
    "    processing_class = extractor,\n",
    "    compute_metrics = compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9602db37-3dcc-4eb0-8492-742234bc464f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959c84e0-d2e2-46f2-9061-5e6cea0c683b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689eec51-9b81-4f54-834b-79fcc8590a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90aba33-c83a-4b33-9e05-84f0f0e965fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372c8dd8-fac0-4f7f-b99d-80bb299ea3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-labeling",
   "language": "python",
   "name": "env-labeling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
