{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349f6542-1b1c-4c9c-9969-7cd8ff1b3a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor, AutoModelForAudioClassification\n",
    "from datasets import load_dataset, Audio\n",
    "import numpy as np\n",
    "import torch\n",
    "import chromadb\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e46f1d-7917-4c11-93d0-22bd886f383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../config.json\", mode = \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    SAMPLING_RATE = data[\"sampling_rate\"]\n",
    "    SEGMENT_LEN = data[\"segment_length\"]\n",
    "    OVERLAP_LEN = data[\"overlap_length\"]\n",
    "    DB_PATH = data[\"database_path\"]\n",
    "    COLLECTION_NAME = data[\"collection_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa76add0-11dd-455b-9e15-6d7c7cd0d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fineTunedExtractor = AutoFeatureExtractor.from_pretrained(\"checkpoints-15-5/checkpoint-32094\")\n",
    "fineTunedModel = AutoModelForAudioClassification.from_pretrained(\"checkpoints-15-5/checkpoint-32094\", device_map = \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eac1a9-a6a1-44d2-ba80-39ce68b39b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Saads/xecanto_birds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c87b5d-e681-4b1a-b730-663b7f0d482b",
   "metadata": {},
   "source": [
    "#### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d18b438-3db5-4282-8ee9-6e9ce885750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def chunk_audio_fine_tuned(audio_array, chunk_length = 15, overlap = 5):\n",
    "#     chunk_length = chunk_length * SAMPLING_RATE\n",
    "#     overlap = overlap * SAMPLING_RATE\n",
    "    \n",
    "#     chunks = []\n",
    "#     start = 0\n",
    "#     while start + chunk_length <= len(audio_array):\n",
    "#         chunks.append(audio_array[start : start + chunk_length])\n",
    "#         start += (chunk_length - overlap)\n",
    "    \n",
    "#     # if start < len(audio_array):\n",
    "#     #     last_chunk = audio_array[start:]\n",
    "#     #     padded_last_chunk = np.pad(last_chunk, (0, chunk_length - len(last_chunk)))\n",
    "#     #     chunks.append(padded_last_chunk)\n",
    "    \n",
    "#     return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c37fed-2220-4b1f-a576-2a6680f3e321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_fine_tuned(row):\n",
    "#     chunks = chunk_audio_fine_tuned(row[\"audio\"][\"array\"])\n",
    "#     row[\"input_values\"] = []\n",
    "#     if(chunks):\n",
    "#         inputs = fineTunedExtractor(chunks, sampling_rate = SAMPLING_RATE, return_tensors = \"pt\")\n",
    "#         row[\"input_values\"] = inputs[\"input_values\"]\n",
    "#     return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063f842d-deb7-4506-958a-402218cc8c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.cast_column(\"audio\", Audio(sampling_rate = SAMPLING_RATE))\n",
    "# dataset = dataset.map(\n",
    "#     preprocess_fine_tuned,\n",
    "#     remove_columns = \"audio\",\n",
    "#     batched = False,\n",
    "#     num_proc = 16,\n",
    "#     writer_batch_size = 200\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b88ba4-288f-406c-8118-b5bc8d321201",
   "metadata": {},
   "source": [
    "#### Whole Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79f8000-8f9e-4009-9ab4-2a6dd8fdc416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fine_tuned(batched_data):    \n",
    "    audio_array = [x[\"array\"] for x in batched_data[\"audio\"]]\n",
    "    inputs = fineTunedExtractor(audio_array, sampling_rate = SAMPLING_RATE)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3102120a-fa89-4999-9fc3-9b59639fe0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate = SAMPLING_RATE))\n",
    "dataset = dataset.map(\n",
    "    preprocess_fine_tuned,\n",
    "    remove_columns = \"audio\",\n",
    "    batched = True,\n",
    "    batch_size = 32,\n",
    "    num_proc = 16,\n",
    "    writer_batch_size = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ef1882-7f88-4c6f-a152-24acb04c12cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chroma_client = chromadb.Client()\n",
    "chroma_client = chromadb.PersistentClient(path = DB_PATH)\n",
    "collection = chroma_client.create_collection(name = COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7ebc24-8868-49eb-be03-25c5b7137c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chroma_client.delete_collection(COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c47305c-5254-4771-8d27-f5d9032caafe",
   "metadata": {},
   "source": [
    "#### Chunked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c806f048-c672-4203-9246-2bdf1d4c019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_embedding_chromaDB(row, index):\n",
    "#     for subIdx, chunk in enumerate(row[\"input_values\"]):\n",
    "#         metadataDict = {\"name\": row[\"common_name\"], \"url\": row[\"url\"]}\n",
    "#         inputs = torch.tensor(chunk)\n",
    "#         with torch.no_grad():\n",
    "#             outputs = fineTunedModel(inputs.unsqueeze(0), output_hidden_states = True)\n",
    "#             logits = outputs.logits\n",
    "#             hidden_states = outputs.hidden_states\n",
    "\n",
    "#         probabilities = torch.nn.functional.softmax(logits, dim = -1)\n",
    "#         values, idxs = torch.topk(probabilities, k = 5)\n",
    "#         values = values.numpy()[0]\n",
    "#         idxs = idxs.numpy()[0]\n",
    "#         for i in range(len(idxs)):\n",
    "#             metadataDict[f\"pred_name_{i + 1}\"] = fineTunedModel.config.id2label[idxs[i]]\n",
    "#             metadataDict[f\"pred_prob_{i + 1}\"] = values[i].item() * 100\n",
    "        \n",
    "#         embeddings = hidden_states[-1]\n",
    "#         embeddings = embeddings.mean(dim = 1)[0].numpy()\n",
    "        \n",
    "#         collection.add(\n",
    "#             embeddings = [embeddings],\n",
    "#             metadatas = [metadataDict],\n",
    "#             ids = [f\"{index}_{subIdx}\"]\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642783bf-d4b0-491d-934c-a7755175c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasetEmbeddings.map(\n",
    "#     add_embedding_chromaDB,\n",
    "#     batched = False,\n",
    "#     num_proc = 1,\n",
    "#     writer_batch_size = 1000,\n",
    "#     with_indices = True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f05471-2bc1-41fa-a4b6-f5959450afd1",
   "metadata": {},
   "source": [
    "#### Whole Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cec6cd9-6689-4ff8-81cd-6612ea2f481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_embedding_chromaDB(row, index):\n",
    "    metadataDict = {\"name\": row[\"common_name\"], \"url\": row[\"url\"]}\n",
    "    inputs = torch.tensor(row[\"input_values\"]).unsqueeze(0).to(torch.device(\"cuda\"))\n",
    "    with torch.no_grad():\n",
    "        outputs = fineTunedModel(inputs, output_hidden_states = True)\n",
    "        logits = outputs.logits\n",
    "        hidden_states = outputs.hidden_states\n",
    "\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim = -1)\n",
    "    values, idxs = torch.topk(probabilities, k = 5)\n",
    "    values = values.cpu().numpy()[0]\n",
    "    idxs = idxs.cpu().numpy()[0]\n",
    "    for i in range(len(idxs)):\n",
    "        metadataDict[f\"pred_name_{i + 1}\"] = fineTunedModel.config.id2label[idxs[i]]\n",
    "        metadataDict[f\"pred_prob_{i + 1}\"] = values[i].item() * 100\n",
    "    \n",
    "    embeddings = hidden_states[-1]\n",
    "    embeddings = embeddings.mean(dim = 1)[0].cpu().numpy()\n",
    "    \n",
    "    collection.add(\n",
    "        embeddings = [embeddings],\n",
    "        metadatas = [metadataDict],\n",
    "        ids = [f\"id_{index}\"]\n",
    "    )\n",
    "\n",
    "    del inputs\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ba2973-289a-43cd-9b17-3eda3b2893d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetEmbeddings.map(\n",
    "    add_embedding_chromaDB,\n",
    "    batched = False,\n",
    "    num_proc = 1,\n",
    "    writer_batch_size = 1000,\n",
    "    with_indices = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924f255e-5497-44aa-891b-efe8c67e8d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f9964f-8a71-4952-ad3c-50eb519c9b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-labeling",
   "language": "python",
   "name": "env-labeling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
